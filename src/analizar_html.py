import os
from bs4 import BeautifulSoup
import re

def extract_extras_from_html(file_path):
    with open(file_path, "r", encoding="utf-8") as f:
        soup = BeautifulSoup(f, "html.parser")

    name = os.path.basename(file_path).replace(".html", "")
    print(f"\nğŸ” Analizando {name}...")

    # Unir todo el texto
    full_text = " ".join(soup.stripped_strings).lower()

    # 1. PolÃ­tica de cancelaciÃ³n
    cancel_match = re.search(r"(cancelaci[oÃ³]n[^\.]{0,100})", full_text)
    cancel_policy = cancel_match.group(1).capitalize() if cancel_match else "No especificada"
    print(f"ğŸ“Œ PolÃ­tica de cancelaciÃ³n: {cancel_policy}")

     # 2. Mascotas
    mascotas_bloque = None
    for div in soup.find_all("div"):
        if div.get_text(strip=True).lower() == "mascotas":
            mascotas_bloque = div.find_next_sibling("div")
            break

    if mascotas_bloque:
        mascotas_texto = mascotas_bloque.get_text(strip=True).lower()
        if "no se admiten" in mascotas_texto or "no se aceptan" in mascotas_texto:
            print("ğŸ¶ Mascotas: ğŸš« No se admiten mascotas")
        elif "se admiten" in mascotas_texto or "se aceptan" in mascotas_texto:
            print("ğŸ¶ Mascotas: âœ… Se admiten mascotas")
        else:
            print("ğŸ¶ Mascotas: â“ Condiciones no claras")
    else:
        print("ğŸ¶ Mascotas: â“ No especificado")

    # 3. Cunas / Camas supletorias
    if "cuna" in full_text:
        print("ğŸ›ï¸ Cunas disponibles")
    if "cama supletoria" in full_text or "camas supletorias" in full_text:
        print("ğŸ›ï¸ Camas supletorias disponibles")
    if "coste adicional" in full_text or "pueden tener coste adicional" in full_text:
        print("ğŸ’° Pueden tener coste adicional")

    # 4. Servicios adicionales
    servicios = [
        "desayuno", "limpieza", "parking", "toallas", "ropa de cama",
        "spa", "masaje", "traslado", "cena"
    ]
    encontrados = [s for s in servicios if s in full_text]
    if encontrados:
        print("ğŸ Servicios adicionales encontrados:")
        for s in encontrados:
            print(f"   - â• {s.capitalize()}")

    # 5. Precios extra (por niÃ±o, persona o noche)
    precios_extras = re.findall(
        r"\bâ‚¬\s?[0-9]{1,3}(?:[.,][0-9]{1,2})?\s?(?:por\s(?:niÃ±[oa]|persona|noche|adulto))",
        full_text
    )
    if precios_extras:
        print("ğŸ’¶ Precios de servicios extra encontrados:")
        for p in precios_extras:
            print(f"   - ğŸ’° {p.strip()}")
    else:
        print("ğŸ’¶ Precios de servicios extra encontrados: Ninguno")

     # 6. PuntuaciÃ³n y nÃºmero de comentarios
    review_component = soup.find("div", {"data-testid": "review-score-component"})
    if review_component:
        all_divs = review_component.find_all("div")
        all_spans = review_component.find_all("span")

        # PuntuaciÃ³n: segundo <div> hijo
        puntuacion = all_divs[1].text.strip() if len(all_divs) > 1 else "No disponible"

        # Comentarios: segundo <span> hijo del Ãºltimo <div>
        comentarios = all_spans[1].text.strip() if len(all_spans) > 1 else "No disponibles"

        print(f"â­ PuntuaciÃ³n: {puntuacion}")
        print(f"ğŸ—£ï¸ Comentarios: {comentarios}")
    else:
        print("â­ PuntuaciÃ³n: No disponible")
        print("ğŸ—£ï¸ Comentarios: No disponibles")

    # 7. HTML completo de las polÃ­ticas de cunas/camas (bloque completo)
    child_policy_block = soup.find("div", {"data-test-id": "child-policies-block"})
    if child_policy_block:
        print("ğŸ§’ PolÃ­ticas de cunas y camas supletorias:")
        print("----------------------------------------------")
        print(child_policy_block.get_text(separator="\n", strip=True))
        print("----------------------------------------------")
    else:
        print("ğŸ§’ PolÃ­ticas de cunas y camas supletorias: âŒ No encontradas")

# Ruta local a los archivos HTML
snapshots_folder = "./html_snapshots"  # â† asegÃºrate de que la ruta es correcta

if os.path.exists(snapshots_folder):
    for filename in os.listdir(snapshots_folder):
        if filename.endswith(".html"):
            extract_extras_from_html(os.path.join(snapshots_folder, filename))
else:
    print("âŒ La carpeta 'html_snapshots' no existe.")
